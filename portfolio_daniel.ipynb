{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Concatenate, Dropout, Subtract, \\\n",
    "                        Flatten, MaxPooling2D, Multiply, Lambda, Add, Dot\n",
    "from tensorflow.keras.backend import constant\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#from keras.engine.topology import Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import random_correlation\n",
    "from sklearn.datasets import make_sparse_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, Concatenate, Dropout, Subtract, \\\n",
    "                        Flatten, MaxPooling2D, Multiply, Lambda, Add, Dot\n",
    "from keras.backend import constant\n",
    "from keras import optimizers\n",
    "\n",
    "#from keras.engine.topology import Layer\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras import initializers\n",
    "from keras.constraints import max_norm\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import random_correlation\n",
    "from sklearn.datasets import make_sparse_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generalisation to multiple stocks -- SET D= # of stocks\n",
    "N=30 # time disrectization\n",
    "m = 3#number of stocks\n",
    "S0 = np.random.normal(1,0.0,m).reshape(1,m) # initial value of the asset(s)\n",
    "X0=1  # initial wealth\n",
    "T=1 # maturity\n",
    "sigma=0.2 # volatility in Black Scholes\n",
    "gamma=0.0\n",
    "sigma = np.abs(np.random.normal(0.2,gamma,m).reshape(m,))\n",
    "mu=np.random.normal(0.1,0.2,m).reshape(1,m)\n",
    "#mu = np.array([0.1,0.3])\n",
    "r=0.05\n",
    "uncertainty = 0.5\n",
    "\n",
    "R=10**5 # number of Trajectories\n",
    "eigenvals = []\n",
    "if m > 1:\n",
    "    for _ in range(m):\n",
    "        eigenvals.append(np.random.uniform(0,m))\n",
    "    eigenvals = m/sum(eigenvals)*np.array(eigenvals)\n",
    "    rho = random_correlation.rvs(eigenvals)\n",
    "\n",
    "#Turn elements ON/OFF\n",
    "VAR_RATE = True\n",
    "INSIDER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.94448415 -0.41938766]\n",
      " [-0.94448415  1.          0.52159065]\n",
      " [-0.41938766  0.52159065  1.        ]]\n",
      "[[0.1 0.1 0.1]]\n"
     ]
    }
   ],
   "source": [
    "# logS= np.zeros((N,R))\n",
    "# logS[0,]=np.log(S0)*np.ones((1,R))\n",
    "\n",
    "# for i in range(R):\n",
    "#     for j in range(N-1):\n",
    "#         increment = np.random.normal(mu*T/N-(sigma)**2*T/(2*N),sigma*np.sqrt(T)/np.sqrt(N))\n",
    "#         logS[j+1,i] =logS[j,i]+increment\n",
    "\n",
    "# S=np.exp(logS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of neural networks for trading strategies\n",
    "\n",
    "#m = D # dimension of price\n",
    "d = 3 # number of layers in strategy\n",
    "n = 32  # nodes in the first but last layers\n",
    "\n",
    "# architecture is the same for all networks\n",
    "layers = []\n",
    "for j in range(N):\n",
    "    for i in range(d):\n",
    "        if i < d-1:\n",
    "            nodes = n\n",
    "            layer = Dense(nodes, activation='tanh',trainable=True,\n",
    "                      kernel_initializer=initializers.RandomNormal(0,0.5),#kernel_initializer='random_normal',\n",
    "                      bias_initializer=initializers.RandomNormal(0,0.5),\n",
    "                      name=str(i)+str(j))\n",
    "        else:\n",
    "            nodes = m\n",
    "            layer = Dense(nodes, activation='linear', trainable=True,\n",
    "                          kernel_initializer=initializers.RandomNormal(0,0.5),#kernel_initializer='random_normal',\n",
    "                          bias_initializer=initializers.RandomNormal(0,0.5),\n",
    "                          name=str(i)+str(j))\n",
    "        layers = layers + [layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the outcoming of trading via neural networks\n",
    "# Inputs is the training set below, containing the price S0, \n",
    "# again we record the trading strategies on separate input variables 'tradeeval' to read them out easily later\n",
    "price = Input(shape=(m,))\n",
    "trade = Input(shape=(m,))\n",
    "tradeeval = Input(shape=(m,))\n",
    "wealth = Input(shape=(1,))\n",
    "inputs = [price]+[trade]+[tradeeval]+[wealth]\n",
    "outputhelper=[]\n",
    "\n",
    "for j in range(N):\n",
    "    #strategy = price\n",
    "    #strategyeval=tradeeval\n",
    "    \n",
    "    #giving the model insider information on the movement of the stocks at next timestep\n",
    "    incr = Input(shape=(m,))\n",
    "    flip = Input(shape=(m,))\n",
    "    insider = Lambda(lambda x: tf.math.sign(x))(incr)\n",
    "    insider = Multiply()([flip,insider]) #flip the information with proba = uncertainty\n",
    "    strategy = Lambda(lambda x: tf.concat(x,axis=1))([price,insider])\n",
    "    strategyeval = Lambda(lambda x: tf.concat(x,axis=1))([tradeeval,insider])    \n",
    "    \n",
    "    for k in range(d):\n",
    "        strategy= layers[k+(j)*d](strategy) # strategy at j is the alpha at j \n",
    "        strategyeval=layers[k+(j)*d](strategyeval)\n",
    "        \n",
    "    #implement strategy dependent interest\n",
    "\n",
    "    helper0a = Lambda(lambda x : K.sum(x,axis=1,keepdims=True))(strategy) #sum over all alphas\n",
    "    helper0b = Lambda(lambda x: K.less(1.0,x))(helper0a) #check if the sum of alphas is larger than 1\n",
    "    helper0b = Lambda(lambda x: tf.cast(x,tf.float32))(helper0b)\n",
    "    r_t = Lambda(lambda x: (mu.mean()-r)*(helper0a-1)*x+r)(helper0b) #adapt interest rate\n",
    "    \n",
    "    #print(r_t.shape)\n",
    "    \n",
    "    #incr = Input(shape=(m,))\n",
    "    logprice= Lambda(lambda x : K.log(x))(price)\n",
    "    logprice = Add()([logprice, incr])\n",
    "    pricenew=Lambda(lambda x : K.exp(x))(logprice)\n",
    "    price=pricenew\n",
    "    logwealth= Lambda(lambda x : K.log(x))(wealth)    \n",
    "   \n",
    "    #logwealth= Lambda(lambda x : x+r*T/N)(logwealth) # <---- r value\n",
    "    helperR = Lambda(lambda x : x*T/N)(r_t)\n",
    "    logwealth = Add()([helperR,logwealth])\n",
    "  \n",
    "    helper1 = Multiply()([strategy, incr])\n",
    "    helper1 = Lambda(lambda x : K.sum(x,axis=1))(helper1)\n",
    "    logwealth = Add()([logwealth, helper1])\n",
    "    if m == 1:\n",
    "        helper2 = Multiply()([strategy, strategy])   \n",
    "        #helper2 = Lambda(lambda x : K.sum(x,axis=1))(helper2)\n",
    "        helper3 = Lambda(lambda x : x*sigma**2/2*T/N)(helper2)\n",
    "        helper3 = Lambda(lambda x: K.sum(x,axis=1))(helper3)\n",
    "        logwealth = Subtract()([logwealth, helper3])\n",
    "       \n",
    "    helper4 = Lambda(lambda x: K.sum(x,axis=1))(strategy)\n",
    "    #helper4 = Lambda(lambda x : x*r*T/N)(helper4) # <----- r value\n",
    "    helper4 = Multiply()([helper4,helperR])\n",
    "    \n",
    "    logwealth = Subtract()([logwealth, helper4])\n",
    "       \n",
    "\n",
    "    sigma_strat = Lambda(lambda x: sigma*x)(strategy) #Multiply the alphas by the sigmas\n",
    "    rho_temp =K.constant(rho,dtype='float32') #Cast correlation matrix into layer\n",
    "    #helper5 = Lambda(lambda x: tf.einsum('ki,ij,jk->k',x[0],x[1],x[2]))([sigma_strat,rho_temp,K.transpose(sigma_strat)])\n",
    "    if m>1 :\n",
    "        helper5 = Lambda(lambda x: K.dot(x,rho_temp))(sigma_strat)\n",
    "        helper5 = Lambda(lambda x: K.dot(x,K.transpose(sigma_strat)))(helper5) #Compute the matrix term\n",
    "        helper5 = Lambda(lambda x: tf.linalg.diag_part(x))(helper5)\n",
    "        helper5 = Lambda(lambda x : 0.5*x*T/N)(helper5)\n",
    "\n",
    "        logwealth = Subtract()([logwealth, helper5])\n",
    "        \n",
    "    \n",
    "    wealthnew=Lambda(lambda x : K.exp(x))(logwealth)# creating the wealth at time j+1\n",
    "    inputs = inputs + [incr] + [flip]\n",
    "    outputhelper = outputhelper + [r_t] +[strategyeval] # here we collect the strategies    \n",
    "    wealth=wealthnew\n",
    "    #print(K.int_shape(logwealth))\n",
    "outputs = wealth\n",
    "#randomendowment = Lambda(lambda x : -0.0*(K.abs(x-1.0)+x-1.0))(price) \n",
    "#outputs = Add()([wealth,randomendowment])\n",
    "outputs = [outputs] + outputhelper\n",
    "#print(K.int_shape(outputhelper[0]))\n",
    "outputs = Concatenate()(outputs)\n",
    "\n",
    "model_MertonD = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ktrain = 10**5\n",
    "initialprice = S0\n",
    "initialwealth = X0\n",
    "\n",
    "#Generate correlated price processes\n",
    "\n",
    "from scipy.linalg import cholesky\n",
    "\n",
    "uncorr = [np.random.normal(0,np.sqrt(T)/np.sqrt(N),(Ktrain,m)) for i in range(N)] #generate uncorrelated price processes\n",
    "\n",
    "if m >1:\n",
    "    corr = []\n",
    "    corr_inside = []\n",
    "    U= cholesky(rho)\n",
    "    #U = np.array([[1,-1],[0,0]])\n",
    "    for unc in uncorr:\n",
    "        corr.append(unc@U*sigma+mu*T/N)#Correlate the processes with the Cholesky decomposition of rho\n",
    "        corr_inside.append(unc@U*sigma+mu*T/N)\n",
    "        corr_inside.append(np.random.choice([-1,1],size=(Ktrain,m),p=[uncertainty,1-uncertainty]))\n",
    "        \n",
    "else:\n",
    "    corr = [np.random.normal(mu*T/N,sigma*np.sqrt(T)/np.sqrt(N),(Ktrain,m)) for i in range(N)]\n",
    "# xtrain consists of the price S0, \n",
    "#the initial hedging being 0, and dummy variables hedgeeval where the strategies are evaluated, \n",
    "#the initial wealth and the increments of the log price process     \n",
    "\n",
    "xtrain = ([np.ones((Ktrain,1))@initialprice] +\n",
    "          [np.zeros((Ktrain,m))]+\n",
    "          [1*np.ones((Ktrain,m))] +\n",
    "          [initialwealth*np.ones((Ktrain,1))] + corr_inside)\n",
    "          #[np.random.normal(mu*T/N,sigma*np.sqrt(T)/np.sqrt(N),(Ktrain,m)) for i in range(N)])\n",
    "\n",
    "ytrain=np.zeros((Ktrain,1+N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.31042667  1.22088607  4.58821489]]\n"
     ]
    }
   ],
   "source": [
    "#Mean-Variance optimisation\n",
    "\n",
    "cov = np.diag(sigma)@rho@np.diag(sigma)\n",
    "r_vec = r*np.ones(m)\n",
    "p = 0.051 #Required return - risk factor\n",
    "premium = (mu-r_vec).reshape(m,)\n",
    "lambd = (p-r)/np.einsum('i,ij,j',premium,cov,premium)\n",
    "w_opt = np.array(lambd*np.matrix(cov)**(-1)@premium)\n",
    "\n",
    "q=0.7\n",
    "w_opt = np.array(np.matrix(cov)**(-1)@(q*mu-r_vec).reshape(m,))\n",
    "\n",
    "print(w_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.879118053860301\n",
      "2.7331246834129694\n"
     ]
    }
   ],
   "source": [
    "#Compute final wealth:\n",
    "wealth = initialwealth*np.ones((Ktrain,1))\n",
    "s_t = np.ones((Ktrain,1))@initialprice\n",
    "logS = np.log(s_t)\n",
    "logX = np.log(np.ones([Ktrain,1]))\n",
    "for incr in corr:\n",
    "    logS += incr\n",
    "    logX += incr@w_opt.T + (1-w_opt.sum())*r*T/N - 0.5*w_opt@cov@w_opt.T*T/N\n",
    "#print(np.exp(logX))\n",
    "print(np.exp(logX).mean())\n",
    "print(np.exp(logX).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true,y_pred):\n",
    "    z = - K.log(y_pred[:,0])#-((y_pred[:,0]**gamma-1)/gamma\n",
    "    z=K.mean(z)\n",
    "    return z\n",
    "#def custom_loss(y_true,y_pred):\n",
    "#    z = K.exp(- y_pred[:,0]*ra)#\n",
    "#    z=K.mean(z)\n",
    "#    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "adam=optimizers.Adam(lr=0.01)\n",
    "\n",
    "model_MertonD.compile(optimizer='adam',loss=custom_loss)#,experimental_run_tf_function=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100000/100000 [==============================] - 44s 438us/step - loss: -0.5425\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    model_MertonD.fit(x=xtrain,y=ytrain, epochs=1,verbose=True,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5485397\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_MertonD.predict(xtrain)\n",
    "print(np.mean(-np.log(y_pred[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1005818 1.0235593 1.5132884 ... 1.2700514 1.0159364 1.1788353]\n",
      "[0.05030418 0.05030418 0.05030418 ... 0.05030418 0.05030418 0.05030418]\n",
      "[0.27702814 0.27702814 0.27702814 ... 0.27702814 0.27702802 0.27702802]\n",
      "[1.1017742 1.1017742 1.1017742 ... 1.1017742 1.1017742 1.1017742]\n"
     ]
    }
   ],
   "source": [
    "for i in range(m+2):\n",
    "    print(y_pred[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean wealth for portfolio with 3 assets: 2.6125715\n",
      "STD of wealth for portfolio with 3 assets: 2.959329\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_pred[:,0],bins = 25,range=(0,10))\n",
    "plt.xlabel('Final wealth')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Portfolio with ' +str(m) + ' assets')\n",
    "plt.show()\n",
    "print('Mean wealth for portfolio with',m,'assets:',np.mean(y_pred[:,0]))\n",
    "print('STD of wealth for portfolio with',m,'assets:',np.std(y_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    plt.plot(S[:,i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X[N-1,:])\n",
    "plt.show()\n",
    "print(np.mean(X[N-1,:]))\n",
    "print(np.std(X[N-1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k=10#Choose a number between 1 and N-1\n",
    "Ktest=60\n",
    "xtest = ([initialprice*np.ones((Ktest,m))] +\n",
    "          [np.zeros((Ktest,m))]+\n",
    "          [np.linspace(0.7,1.5,Ktest)] +#change this if you go to higher dimensions\n",
    "          [initialwealth*np.ones((Ktest,m))]+\n",
    "          [np.random.normal(mu*T/N,sigma*np.sqrt(T)/np.sqrt(N),(Ktest,m)) for i in range(N)])\n",
    "\n",
    "\n",
    "#Comparison of learned and true alpha\n",
    "s=np.linspace(0.7,1.5,Ktest)\n",
    "\n",
    "for k in range(1,N):\n",
    "    truestrat=(mu-r)/(sigma**2*(1-gamma))*np.ones(Ktest)\n",
    "    learnedstrat=model_Merton.predict(xtest)[:,k]\n",
    "    plt.plot(s,learnedstrat,s,truestrat)\n",
    "plt.show()\n",
    "print((mu-r)/(sigma**2*(1-gamma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
