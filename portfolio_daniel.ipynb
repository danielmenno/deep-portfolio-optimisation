{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Concatenate, Dropout, Subtract, \\\n",
    "                        Flatten, MaxPooling2D, Multiply, Lambda, Add, Dot\n",
    "from tensorflow.keras.backend import constant\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#from keras.engine.topology import Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import random_correlation\n",
    "from sklearn.datasets import make_sparse_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, Concatenate, Dropout, Subtract, \\\n",
    "                        Flatten, MaxPooling2D, Multiply, Lambda, Add, Dot\n",
    "from keras.backend import constant\n",
    "from keras import optimizers\n",
    "\n",
    "#from keras.engine.topology import Layer\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras import initializers\n",
    "from keras.constraints import max_norm\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import random_correlation\n",
    "from sklearn.datasets import make_sparse_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.63745018 -0.51833216]\n",
      " [-0.63745018  1.          0.58050569]\n",
      " [-0.51833216  0.58050569  1.        ]]\n",
      "[[0.16147445 0.05042301 0.14010771]]\n"
     ]
    }
   ],
   "source": [
    "## Generalisation to multiple stocks -- SET D= # of stocks\n",
    "N=30 # time disrectization\n",
    "m = 3#number of stocks\n",
    "S0 = np.random.normal(1,0.0,m).reshape(1,m) # initial value of the asset(s)\n",
    "X0=1  # initial wealth\n",
    "T=1 # maturity\n",
    "sigma=0.2 # volatility in Black Scholes\n",
    "sigma = np.abs(np.random.normal(0.5,0.2,m).reshape(m,))\n",
    "mu=np.random.normal(0.1,0.05,m).reshape(1,m)\n",
    "#mu = np.array([0.1,0.3])\n",
    "r=0.02\n",
    "gamma=0.0\n",
    "R=10**5 # number of Trajectories\n",
    "eigenvals = []\n",
    "if m > 1:\n",
    "    for _ in range(m):\n",
    "        eigenvals.append(np.random.uniform(0,m))\n",
    "    eigenvals = m/sum(eigenvals)*np.array(eigenvals)\n",
    "    rho = random_correlation.rvs(eigenvals)\n",
    "print(rho)\n",
    "print(mu)\n",
    "#rho = [[1,0],[0,1]]\n",
    "# logS= np.zeros((N,R))\n",
    "# logS[0,]=np.log(S0)*np.ones((1,R))\n",
    "\n",
    "# for i in range(R):\n",
    "#     for j in range(N-1):\n",
    "#         increment = np.random.normal(mu*T/N-(sigma)**2*T/(2*N),sigma*np.sqrt(T)/np.sqrt(N))\n",
    "#         logS[j+1,i] =logS[j,i]+increment\n",
    "\n",
    "# S=np.exp(logS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of neural networks for trading strategies\n",
    "\n",
    "#m = D # dimension of price\n",
    "d = 3 # number of layers in strategy\n",
    "n = 32  # nodes in the first but last layers\n",
    "\n",
    "# architecture is the same for all networks\n",
    "layers = []\n",
    "for j in range(N):\n",
    "    for i in range(d):\n",
    "        if i < d-1:\n",
    "            nodes = n\n",
    "            layer = Dense(nodes, activation='tanh',trainable=True,\n",
    "                      kernel_initializer=initializers.RandomNormal(0,0.5),#kernel_initializer='random_normal',\n",
    "                      bias_initializer=initializers.RandomNormal(0,0.5),\n",
    "                      name=str(i)+str(j))\n",
    "        else:\n",
    "            nodes = m\n",
    "            layer = Dense(nodes, activation='linear', trainable=True,\n",
    "                          kernel_initializer=initializers.RandomNormal(0,0.5),#kernel_initializer='random_normal',\n",
    "                          bias_initializer=initializers.RandomNormal(0,0.5),\n",
    "                          name=str(i)+str(j))\n",
    "        layers = layers + [layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Implementing the outcoming of trading via neural networks\n",
    "# Inputs is the training set below, containing the price S0, \n",
    "# again we record the trading strategies on separate input variables 'tradeeval' to read them out easily later\n",
    "price = Input(shape=(m,))\n",
    "trade = Input(shape=(m,))\n",
    "tradeeval = Input(shape=(m,))\n",
    "wealth = Input(shape=(1,))\n",
    "inputs = [price]+[trade]+[tradeeval]+[wealth]\n",
    "outputhelper=[]\n",
    "\n",
    "for j in range(N):\n",
    "    strategy = price\n",
    "    strategyeval=tradeeval\n",
    "    for k in range(d):\n",
    "        strategy= layers[k+(j)*d](strategy) # strategy at j is the alpha at j \n",
    "        strategyeval=layers[k+(j)*d](strategyeval)\n",
    "        \n",
    "    #implement strategy dependent interest\n",
    "\n",
    "    helper0a = Lambda(lambda x : K.sum(x,axis=1,keepdims=True))(strategy)\n",
    "    helper0b = Lambda(lambda x: K.less(1.0,x))(helper0a)\n",
    "    helper0b = Lambda(lambda x: tf.cast(x,tf.float32))(helper0b)\n",
    "    r_t = Lambda(lambda x: (mu.mean()-r)*(helper0a-1)*x+r)(helper0b)\n",
    "    \n",
    "    #print(r_t.shape)\n",
    "    \n",
    "    incr = Input(shape=(m,))\n",
    "    logprice= Lambda(lambda x : K.log(x))(price)\n",
    "    logprice = Add()([logprice, incr])\n",
    "    pricenew=Lambda(lambda x : K.exp(x))(logprice)\n",
    "    price=pricenew\n",
    "    logwealth= Lambda(lambda x : K.log(x))(wealth)    \n",
    "   \n",
    "    #logwealth= Lambda(lambda x : x+r*T/N)(logwealth) # <---- r value\n",
    "    helperR = Lambda(lambda x : x*T/N)(r_t)\n",
    "    logwealth = Add()([helperR,logwealth])\n",
    "  \n",
    "    helper1 = Multiply()([strategy, incr])\n",
    "    helper1 = Lambda(lambda x : K.sum(x,axis=1))(helper1)\n",
    "    logwealth = Add()([logwealth, helper1])\n",
    "    if m == 1:\n",
    "        helper2 = Multiply()([strategy, strategy])   \n",
    "        #helper2 = Lambda(lambda x : K.sum(x,axis=1))(helper2)\n",
    "        helper3 = Lambda(lambda x : x*sigma**2/2*T/N)(helper2)\n",
    "        helper3 = Lambda(lambda x: K.sum(x,axis=1))(helper3)\n",
    "        logwealth = Subtract()([logwealth, helper3])\n",
    "       \n",
    "    helper4 = Lambda(lambda x: K.sum(x,axis=1))(strategy)\n",
    "    #helper4 = Lambda(lambda x : x*r*T/N)(helper4) # <----- r value\n",
    "    helper4 = Multiply()([helper4,helperR])\n",
    "    \n",
    "    logwealth = Subtract()([logwealth, helper4])\n",
    "       \n",
    "    #Add correlation terms\n",
    "#     if m > 1:\n",
    "#         for i in range(m):\n",
    "#             strat_i = Lambda(lambda x: x[:,i])(strategy)\n",
    "#             for j in range(i+1,m):\n",
    "#                 strat_j = Lambda(lambda x: x[:,j])(strategy)\n",
    "#                 helper5 = Multiply()([strat_i,strat_j])\n",
    "#                 helper5 = Lambda(lambda x: x*sigma[i]*sigma[j]*rho[i][j]*T/N)(helper5)        \n",
    "\n",
    "    sigma_strat = Lambda(lambda x: sigma*x)(strategy)\n",
    "    rho_temp =K.constant(rho,dtype='float32')\n",
    "    #helper5 = Lambda(lambda x: tf.einsum('ki,ij,jk->k',x[0],x[1],x[2]))([sigma_strat,rho_temp,K.transpose(sigma_strat)])\n",
    "    if m>1 :\n",
    "        helper5 = Lambda(lambda x: K.dot(x,rho_temp))(sigma_strat)\n",
    "        helper5 = Lambda(lambda x: K.dot(x,K.transpose(sigma_strat)))(helper5)\n",
    "        helper5 = Lambda(lambda x: tf.linalg.diag_part(x))(helper5)\n",
    "        helper5 = Lambda(lambda x : 0.5*x*T/N)(helper5)\n",
    "\n",
    "        logwealth = Subtract()([logwealth, helper5])\n",
    "    wealthnew=Lambda(lambda x : K.exp(x))(logwealth)# creating the wealth at time j+1\n",
    "    inputs = inputs + [incr]\n",
    "    outputhelper = outputhelper + [r_t] +[strategyeval] # here we collect the strategies    \n",
    "    wealth=wealthnew\n",
    "    #print(K.int_shape(logwealth))\n",
    "outputs = wealth\n",
    "#randomendowment = Lambda(lambda x : -0.0*(K.abs(x-1.0)+x-1.0))(price) \n",
    "#outputs = Add()([wealth,randomendowment])\n",
    "outputs = [outputs] + outputhelper\n",
    "#print(K.int_shape(outputhelper[0]))\n",
    "outputs = Concatenate()(outputs)\n",
    "\n",
    "model_MertonD = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ktrain = 10**5\n",
    "initialprice = S0\n",
    "initialwealth = X0\n",
    "\n",
    "#Generate correlated price processes\n",
    "\n",
    "from scipy.linalg import cholesky\n",
    "\n",
    "uncorr = [np.random.normal(0,np.sqrt(T)/np.sqrt(N),(Ktrain,m)) for i in range(N)]\n",
    "\n",
    "if m >1:\n",
    "    corr = []\n",
    "    U= cholesky(rho)\n",
    "    #U = np.array([[1,-1],[0,0]])\n",
    "    for unc in uncorr:\n",
    "        corr.append(unc@U*sigma+mu*T/N)\n",
    "else:\n",
    "    corr = [np.random.normal(mu*T/N,sigma*np.sqrt(T)/np.sqrt(N),(Ktrain,m)) for i in range(N)]\n",
    "# xtrain consists of the price S0, \n",
    "#the initial hedging being 0, and dummy variables hedgeeval where the strategies are evaluated, \n",
    "#the initial wealth and the increments of the log price process     \n",
    "\n",
    "xtrain = ([np.ones((Ktrain,1))@initialprice] +\n",
    "          [np.zeros((Ktrain,m))]+\n",
    "          [1*np.ones((Ktrain,m))] +\n",
    "          [initialwealth*np.ones((Ktrain,1))] + corr)\n",
    "          #[np.random.normal(mu*T/N,sigma*np.sqrt(T)/np.sqrt(N),(Ktrain,m)) for i in range(N)])\n",
    "\n",
    "ytrain=np.zeros((Ktrain,1+N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.44819313 13.20019685  6.55771103]]\n"
     ]
    }
   ],
   "source": [
    "#Mean-Variance optimisation\n",
    "\n",
    "cov = np.diag(sigma)@rho@np.diag(sigma)\n",
    "r_vec = r*np.ones(m)\n",
    "p = 0.2\n",
    "premium = (mu-r_vec).reshape(m,)\n",
    "lambd = (p-r)/np.einsum('i,ij,j',premium,cov,premium)\n",
    "w_opt = np.array(lambd*np.matrix(cov)**(-1)@premium)\n",
    "print(w_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.862893083936015\n"
     ]
    }
   ],
   "source": [
    "#Compute final wealth:\n",
    "\n",
    "s_t = np.ones((Ktrain,1))@initialprice\n",
    "for incr in corr:\n",
    "    s_t += incr\n",
    "final_wealth = s_t@w_opt.T+(1-w_opt.sum())*r\n",
    "print(final_wealth.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true,y_pred):\n",
    "    z = - K.log(y_pred[:,0])#-((y_pred[:,0]**gamma-1)/gamma\n",
    "    z=K.mean(z)\n",
    "    return z\n",
    "#def custom_loss(y_true,y_pred):\n",
    "#    z = K.exp(- y_pred[:,0]*ra)#\n",
    "#    z=K.mean(z)\n",
    "#    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "adam=optimizers.Adam(lr=0.01)\n",
    "\n",
    "model_MertonD.compile(optimizer='adam',loss=custom_loss)#,experimental_run_tf_function=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples\n",
      "100000/100000 [==============================] - 34s 340us/sample - loss: -0.0878\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    model_MertonD.fit(x=xtrain,y=ytrain, epochs=1,verbose=True,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.093480974\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_MertonD.predict(xtrain)\n",
    "print(np.mean(-np.log(y_pred[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1005818 1.0235593 1.5132884 ... 1.2700514 1.0159364 1.1788353]\n",
      "[0.05030418 0.05030418 0.05030418 ... 0.05030418 0.05030418 0.05030418]\n",
      "[0.27702814 0.27702814 0.27702814 ... 0.27702814 0.27702802 0.27702802]\n",
      "[1.1017742 1.1017742 1.1017742 ... 1.1017742 1.1017742 1.1017742]\n"
     ]
    }
   ],
   "source": [
    "for i in range(m+2):\n",
    "    print(y_pred[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 91)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median wealth for portfolio with 2 assets: 1.1286039\n",
      "STD of wealth for portfolio with 2 assets: 0.112190515\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_pred[:,0],bins = 25,range=(0,10))\n",
    "plt.xlabel('Final wealth')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Portfolio with ' +str(m) + ' assets')\n",
    "plt.show()\n",
    "print('Median wealth for portfolio with',m,'assets:',np.mean(y_pred[:,0]))\n",
    "print('STD of wealth for portfolio with',m,'assets:',np.std(y_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    plt.plot(S[:,i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X[N-1,:])\n",
    "plt.show()\n",
    "print(np.mean(X[N-1,:]))\n",
    "print(np.std(X[N-1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k=10#Choose a number between 1 and N-1\n",
    "Ktest=60\n",
    "xtest = ([initialprice*np.ones((Ktest,m))] +\n",
    "          [np.zeros((Ktest,m))]+\n",
    "          [np.linspace(0.7,1.5,Ktest)] +#change this if you go to higher dimensions\n",
    "          [initialwealth*np.ones((Ktest,m))]+\n",
    "          [np.random.normal(mu*T/N,sigma*np.sqrt(T)/np.sqrt(N),(Ktest,m)) for i in range(N)])\n",
    "\n",
    "\n",
    "#Comparison of learned and true alpha\n",
    "s=np.linspace(0.7,1.5,Ktest)\n",
    "\n",
    "for k in range(1,N):\n",
    "    truestrat=(mu-r)/(sigma**2*(1-gamma))*np.ones(Ktest)\n",
    "    learnedstrat=model_Merton.predict(xtest)[:,k]\n",
    "    plt.plot(s,learnedstrat,s,truestrat)\n",
    "plt.show()\n",
    "print((mu-r)/(sigma**2*(1-gamma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
