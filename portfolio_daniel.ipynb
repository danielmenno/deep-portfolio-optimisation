{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Concatenate, Dropout, Subtract, \\\n",
    "                        Flatten, MaxPooling2D, Multiply, Lambda, Add, Dot\n",
    "from tensorflow.keras.backend import constant\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#from keras.engine.topology import Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import random_correlation\n",
    "from sklearn.datasets import make_sparse_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, Concatenate, Dropout, Subtract, \\\n",
    "                        Flatten, MaxPooling2D, Multiply, Lambda, Add, Dot\n",
    "from keras.backend import constant\n",
    "from keras import optimizers\n",
    "\n",
    "#from keras.engine.topology import Layer\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras import initializers\n",
    "from keras.constraints import max_norm\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import random_correlation\n",
    "from sklearn.datasets import make_sparse_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.1792146  -0.66806377]\n",
      " [ 0.1792146   1.          0.20513228]\n",
      " [-0.66806377  0.20513228  1.        ]]\n",
      "[[0.1 0.1 0.1]]\n"
     ]
    }
   ],
   "source": [
    "## Generalisation to multiple stocks -- SET D= # of stocks\n",
    "N=30 # time disrectization\n",
    "m = 3#number of stocks\n",
    "S0 = np.random.normal(1,0.0,m).reshape(1,m) # initial value of the asset(s)\n",
    "X0=1  # initial wealth\n",
    "T=1 # maturity\n",
    "sigma=0.2 # volatility in Black Scholes\n",
    "sigma = np.abs(np.random.normal(0.5,0.0,m).reshape(m,))\n",
    "mu=np.random.normal(0.1,0.00,m).reshape(1,m)\n",
    "#mu = np.array([0.1,0.3])\n",
    "r=0.02\n",
    "gamma=0.0\n",
    "R=10**5 # number of Trajectories\n",
    "eigenvals = []\n",
    "if m > 1:\n",
    "    for _ in range(m):\n",
    "        eigenvals.append(np.random.uniform(0,m))\n",
    "    eigenvals = m/sum(eigenvals)*np.array(eigenvals)\n",
    "    rho = random_correlation.rvs(eigenvals)\n",
    "print(rho)\n",
    "print(mu)\n",
    "#rho = [[1,0],[0,1]]\n",
    "# logS= np.zeros((N,R))\n",
    "# logS[0,]=np.log(S0)*np.ones((1,R))\n",
    "\n",
    "# for i in range(R):\n",
    "#     for j in range(N-1):\n",
    "#         increment = np.random.normal(mu*T/N-(sigma)**2*T/(2*N),sigma*np.sqrt(T)/np.sqrt(N))\n",
    "#         logS[j+1,i] =logS[j,i]+increment\n",
    "\n",
    "# S=np.exp(logS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of neural networks for trading strategies\n",
    "\n",
    "#m = D # dimension of price\n",
    "d = 3 # number of layers in strategy\n",
    "n = 32  # nodes in the first but last layers\n",
    "\n",
    "# architecture is the same for all networks\n",
    "layers = []\n",
    "for j in range(N):\n",
    "    for i in range(d):\n",
    "        if i < d-1:\n",
    "            nodes = n\n",
    "            layer = Dense(nodes, activation='tanh',trainable=True,\n",
    "                      kernel_initializer=initializers.RandomNormal(0,0.5),#kernel_initializer='random_normal',\n",
    "                      bias_initializer=initializers.RandomNormal(0,0.5),\n",
    "                      name=str(i)+str(j))\n",
    "        else:\n",
    "            nodes = m\n",
    "            layer = Dense(nodes, activation='linear', trainable=True,\n",
    "                          kernel_initializer=initializers.RandomNormal(0,0.5),#kernel_initializer='random_normal',\n",
    "                          bias_initializer=initializers.RandomNormal(0,0.5),\n",
    "                          name=str(i)+str(j))\n",
    "        layers = layers + [layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the outcoming of trading via neural networks\n",
    "# Inputs is the training set below, containing the price S0, \n",
    "# again we record the trading strategies on separate input variables 'tradeeval' to read them out easily later\n",
    "price = Input(shape=(m,))\n",
    "trade = Input(shape=(m,))\n",
    "tradeeval = Input(shape=(m,))\n",
    "wealth = Input(shape=(1,))\n",
    "inputs = [price]+[trade]+[tradeeval]+[wealth]\n",
    "outputhelper=[]\n",
    "\n",
    "for j in range(N):\n",
    "    strategy = price\n",
    "    strategyeval=tradeeval\n",
    "    for k in range(d):\n",
    "        strategy= layers[k+(j)*d](strategy) # strategy at j is the alpha at j \n",
    "        strategyeval=layers[k+(j)*d](strategyeval)\n",
    "        \n",
    "    #implement strategy dependent interest\n",
    "\n",
    "    helper0a = Lambda(lambda x : K.sum(x,axis=1,keepdims=True))(strategy)\n",
    "    helper0b = Lambda(lambda x: K.less(1.0,x))(helper0a)\n",
    "    helper0b = Lambda(lambda x: tf.cast(x,tf.float32))(helper0b)\n",
    "    r_t = Lambda(lambda x: (mu.mean()-r)*(helper0a-1)*0+r)(helper0b)\n",
    "    \n",
    "    #print(r_t.shape)\n",
    "    \n",
    "    incr = Input(shape=(m,))\n",
    "    logprice= Lambda(lambda x : K.log(x))(price)\n",
    "    logprice = Add()([logprice, incr])\n",
    "    pricenew=Lambda(lambda x : K.exp(x))(logprice)\n",
    "    price=pricenew\n",
    "    logwealth= Lambda(lambda x : K.log(x))(wealth)    \n",
    "   \n",
    "    #logwealth= Lambda(lambda x : x+r*T/N)(logwealth) # <---- r value\n",
    "    helperR = Lambda(lambda x : x*T/N)(r_t)\n",
    "    logwealth = Add()([helperR,logwealth])\n",
    "  \n",
    "    helper1 = Multiply()([strategy, incr])\n",
    "    helper1 = Lambda(lambda x : K.sum(x,axis=1))(helper1)\n",
    "    logwealth = Add()([logwealth, helper1])\n",
    "    if m == 1:\n",
    "        helper2 = Multiply()([strategy, strategy])   \n",
    "        #helper2 = Lambda(lambda x : K.sum(x,axis=1))(helper2)\n",
    "        helper3 = Lambda(lambda x : x*sigma**2/2*T/N)(helper2)\n",
    "        helper3 = Lambda(lambda x: K.sum(x,axis=1))(helper3)\n",
    "        logwealth = Subtract()([logwealth, helper3])\n",
    "       \n",
    "    helper4 = Lambda(lambda x: K.sum(x,axis=1))(strategy)\n",
    "    #helper4 = Lambda(lambda x : x*r*T/N)(helper4) # <----- r value\n",
    "    helper4 = Multiply()([helper4,helperR])\n",
    "    \n",
    "    logwealth = Subtract()([logwealth, helper4])\n",
    "       \n",
    "    #Add correlation terms\n",
    "#     if m > 1:\n",
    "#         for i in range(m):\n",
    "#             strat_i = Lambda(lambda x: x[:,i])(strategy)\n",
    "#             for j in range(i+1,m):\n",
    "#                 strat_j = Lambda(lambda x: x[:,j])(strategy)\n",
    "#                 helper5 = Multiply()([strat_i,strat_j])\n",
    "#                 helper5 = Lambda(lambda x: x*sigma[i]*sigma[j]*rho[i][j]*T/N)(helper5)        \n",
    "\n",
    "    sigma_strat = Lambda(lambda x: sigma*x)(strategy)\n",
    "    rho_temp =K.constant(rho,dtype='float32')\n",
    "    #helper5 = Lambda(lambda x: tf.einsum('ki,ij,jk->k',x[0],x[1],x[2]))([sigma_strat,rho_temp,K.transpose(sigma_strat)])\n",
    "    if m>1 :\n",
    "        helper5 = Lambda(lambda x: K.dot(x,rho_temp))(sigma_strat)\n",
    "        helper5 = Lambda(lambda x: K.dot(x,K.transpose(sigma_strat)))(helper5)\n",
    "        helper5 = Lambda(lambda x: tf.linalg.diag_part(x))(helper5)\n",
    "        helper5 = Lambda(lambda x : 0.5*x*T/N)(helper5)\n",
    "\n",
    "        logwealth = Subtract()([logwealth, helper5])\n",
    "    wealthnew=Lambda(lambda x : K.exp(x))(logwealth)# creating the wealth at time j+1\n",
    "    inputs = inputs + [incr]\n",
    "    outputhelper = outputhelper + [r_t] +[strategyeval] # here we collect the strategies    \n",
    "    wealth=wealthnew\n",
    "    #print(K.int_shape(logwealth))\n",
    "outputs = wealth\n",
    "#randomendowment = Lambda(lambda x : -0.0*(K.abs(x-1.0)+x-1.0))(price) \n",
    "#outputs = Add()([wealth,randomendowment])\n",
    "outputs = [outputs] + outputhelper\n",
    "#print(K.int_shape(outputhelper[0]))\n",
    "outputs = Concatenate()(outputs)\n",
    "\n",
    "model_MertonD = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ktrain = 10**5\n",
    "initialprice = S0\n",
    "initialwealth = X0\n",
    "\n",
    "#Generate correlated price processes\n",
    "\n",
    "from scipy.linalg import cholesky\n",
    "\n",
    "uncorr = [np.random.normal(0,np.sqrt(T)/np.sqrt(N),(Ktrain,m)) for i in range(N)]\n",
    "\n",
    "if m >1:\n",
    "    corr = []\n",
    "    U= cholesky(rho)\n",
    "    #U = np.array([[1,-1],[0,0]])\n",
    "    for unc in uncorr:\n",
    "        corr.append(unc@U*sigma+mu*T/N)\n",
    "else:\n",
    "    corr = [np.random.normal(mu*T/N,sigma*np.sqrt(T)/np.sqrt(N),(Ktrain,m)) for i in range(N)]\n",
    "# xtrain consists of the price S0, \n",
    "#the initial hedging being 0, and dummy variables hedgeeval where the strategies are evaluated, \n",
    "#the initial wealth and the increments of the log price process     \n",
    "\n",
    "xtrain = ([np.ones((Ktrain,1))@initialprice] +\n",
    "          [np.zeros((Ktrain,m))]+\n",
    "          [1*np.ones((Ktrain,m))] +\n",
    "          [initialwealth*np.ones((Ktrain,1))] + corr)\n",
    "          #[np.random.normal(mu*T/N,sigma*np.sqrt(T)/np.sqrt(N),(Ktrain,m)) for i in range(N)])\n",
    "\n",
    "ytrain=np.zeros((Ktrain,1+N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.57230697 -0.16701348  2.57490195]]\n"
     ]
    }
   ],
   "source": [
    "#Mean-Variance optimisation\n",
    "\n",
    "cov = np.diag(sigma)@rho@np.diag(sigma)\n",
    "r_vec = r*np.ones(m)\n",
    "p = 0.03 #Required return - risk factor\n",
    "premium = (mu-r_vec).reshape(m,)\n",
    "lambd = (p-r)/np.einsum('i,ij,j',premium,cov,premium)\n",
    "w_opt = np.array(lambd*np.matrix(cov)**(-1)@premium)\n",
    "print(w_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.14106335]\n",
      " [0.80989106]\n",
      " [1.32844245]\n",
      " ...\n",
      " [1.3461714 ]\n",
      " [0.88258946]\n",
      " [0.30490842]]\n",
      "1.5207108268734906\n",
      "2.017561808548533\n"
     ]
    }
   ],
   "source": [
    "#Compute final wealth:\n",
    "wealth = initialwealth*np.ones((Ktrain,1))\n",
    "s_t = np.ones((Ktrain,1))@initialprice\n",
    "logS = np.log(s_t)\n",
    "logX = np.log(np.ones([Ktrain,1]))\n",
    "for incr in corr:\n",
    "    logS += incr\n",
    "    logX += incr@w_opt.T + (1-w_opt.sum())*r*T/N - 0.5*w_opt@cov@w_opt.T*T/N\n",
    "print(np.exp(logX))\n",
    "print(np.exp(logX).mean())\n",
    "print(np.exp(logX).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true,y_pred):\n",
    "    z = - K.log(y_pred[:,0])#-((y_pred[:,0]**gamma-1)/gamma\n",
    "    z=K.mean(z)\n",
    "    return z\n",
    "#def custom_loss(y_true,y_pred):\n",
    "#    z = K.exp(- y_pred[:,0]*ra)#\n",
    "#    z=K.mean(z)\n",
    "#    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "adam=optimizers.Adam(lr=0.01)\n",
    "\n",
    "model_MertonD.compile(optimizer='adam',loss=custom_loss)#,experimental_run_tf_function=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100000/100000 [==============================] - 35s 349us/step - loss: -0.1647\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    model_MertonD.fit(x=xtrain,y=ytrain, epochs=1,verbose=True,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18797313\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_MertonD.predict(xtrain)\n",
    "print(np.mean(-np.log(y_pred[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1005818 1.0235593 1.5132884 ... 1.2700514 1.0159364 1.1788353]\n",
      "[0.05030418 0.05030418 0.05030418 ... 0.05030418 0.05030418 0.05030418]\n",
      "[0.27702814 0.27702814 0.27702814 ... 0.27702814 0.27702802 0.27702802]\n",
      "[1.1017742 1.1017742 1.1017742 ... 1.1017742 1.1017742 1.1017742]\n"
     ]
    }
   ],
   "source": [
    "for i in range(m+2):\n",
    "    print(y_pred[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 91)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median wealth for portfolio with 3 assets: 1.4707983\n",
      "STD of wealth for portfolio with 3 assets: 1.0369738\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_pred[:,0],bins = 25,range=(0,10))\n",
    "plt.xlabel('Final wealth')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Portfolio with ' +str(m) + ' assets')\n",
    "plt.show()\n",
    "print('Median wealth for portfolio with',m,'assets:',np.mean(y_pred[:,0]))\n",
    "print('STD of wealth for portfolio with',m,'assets:',np.std(y_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    plt.plot(S[:,i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X[N-1,:])\n",
    "plt.show()\n",
    "print(np.mean(X[N-1,:]))\n",
    "print(np.std(X[N-1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k=10#Choose a number between 1 and N-1\n",
    "Ktest=60\n",
    "xtest = ([initialprice*np.ones((Ktest,m))] +\n",
    "          [np.zeros((Ktest,m))]+\n",
    "          [np.linspace(0.7,1.5,Ktest)] +#change this if you go to higher dimensions\n",
    "          [initialwealth*np.ones((Ktest,m))]+\n",
    "          [np.random.normal(mu*T/N,sigma*np.sqrt(T)/np.sqrt(N),(Ktest,m)) for i in range(N)])\n",
    "\n",
    "\n",
    "#Comparison of learned and true alpha\n",
    "s=np.linspace(0.7,1.5,Ktest)\n",
    "\n",
    "for k in range(1,N):\n",
    "    truestrat=(mu-r)/(sigma**2*(1-gamma))*np.ones(Ktest)\n",
    "    learnedstrat=model_Merton.predict(xtest)[:,k]\n",
    "    plt.plot(s,learnedstrat,s,truestrat)\n",
    "plt.show()\n",
    "print((mu-r)/(sigma**2*(1-gamma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
